:imagesdir: ../assets/images
[#model-analytics]
= Usage Analytics and Reporting

In this module, you're stepping into the role of a **technical decision maker** - someone responsible not just for building AI services, but for understanding their business impact.

You've deployed, exposed, and consumed a model. Now it's time to ask:

* How is it being used?
* Who's using it the most?
* What's the cost and what's the return?

Let's walk through how to leverage our API Gateway analytics to answer those questions.

== Why This Matters

As AI adoption grows, visibility is critical. Organizations need to track: 

* Model/API usage by team or app
* Call volume over time
* Popular endpoints
* Cost-to-value
* Infrastructure impact (e.g. GPU usage)

This insight enables:

* Cost attribution (per team, per model, per environment)

* Capacity planning (predict future GPU or API scale needs)

* Understanding ROI for AI workloads

[#analytics-overview]
== Check Model Usage

* Go to your 3Scale Developer Portal dashboard:

https://maas.{openshift_cluster_ingress_domain}

* Click on the `Statistics` tab at the top.
+
[.bordershadow]
image::04/04-dev-stats-panel.png[width="75%"]

* From the drop-down, select the application you have been using to see detailed metrics: 

[.bordershadow]
image::04/04-dev-stats-metrics.png[width="75%"]

As a developer, you can view the statistics of your applications and monitor their usage. You can also view the number of calls made to the API, and the different methods used.

This helps you monitor how your AI service is actually being used by your teams.

NOTE: You will not see the Llama Stack usage metrics here due to the configuration of this workshop. You will see the metrics from the code assistant activities.

== Summary: Analytics as a Strategy Tool

Usage metrics aren't just operational, they inform:

* Future capacity planning
* Internal billing models (chargeback)
* Service quality assessments
* Product direction based on user trends.