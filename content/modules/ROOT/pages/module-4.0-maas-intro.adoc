:imagesdir: ../assets/images

[#maas_introduction]
= Setting Up Model-as-a-Service Infrastructure

== Introduction: The Hidden Cost of Infrastructure-as-a-Service

As a **platform engineer**, you may inherit clusters filled with GPU nodes and eager teams. But when infrastructure is self-service with no clear guardrails in place, problems can quickly emerge:

- Teams struggle to correctly request and size GPU resources
// - Multiple teams may deploy identical models, duplicating effort
- Expensive GPUs remain idle or become overloaded
- Infrastructure costs escalate without clear accountability
// - Developers need model access, not GPU management complexity

== Models-as-a-Service: A Better Abstraction for AI at Scale

To address these challenges as a platform engineer, you will design a centralized, reusable, and secure model-serving layer:

**Centralized Model Management**

* Platform teams deploy and maintain models with proper lifecycle management
* Versioning, rollbacks, and testing become standardized processes

**Secure API Gateway**

* All model access goes through authenticated, rate-limited endpoints
* Full observability and monitoring across all model interactions

**Developer-Friendly Access**

* Developers consume models without managing underlying hardware
* Teams focus on building applications, agents, and features powered by AI

**Efficient Resource Utilization**

* GPU resources are pooled and shared across the organization
* Eliminates waste while ensuring fair access and cost control



[cols="1,1", frame=none, grid=cols]
|===
a|[.bordershadow]
image::02/iaas.png[width="100%"]
a|[.bordershadow]
image::02/maas.png[width="100%"]
|===

== Module 1 Goals: Step into the Platform Engineer Role

In this first module, you will take your first step into the role of a platform engineer enabling Generative AI at scale.

**What You'll Accomplish:**

* Explore OpenShift AI architecture and its enterprise model-serving capabilities
* Configure an API Gateway to securely expose model endpoints to end users

**Your Learning Outcome:**

By completing this module, you'll understand how to transform raw GPU infrastructure into a scalable, manageable Model-as-a-Service foundation. This platform will serve as the cornerstone for AI-powered applications across your organization.

== Deploy the Granite Model (DO NOT SKIP)

Before we do anything, we need to ensure we have the right model deployed for our activities. We may already have a Granite model deployed, but for this exercise we have to use some different configurations to work with the 3scale API Management product. 

Uninstall your current Granite helm deployment:

[source,sh,role=execute]
----
helm uninstall granite-8b
----

Deploy the Granite model with the following command (ensure you are at the right path locally in your terminal to execute this command):

[source,sh,role=execute]
----
oc apply -k workshop_code/granite-8b -n llm-hosting
----