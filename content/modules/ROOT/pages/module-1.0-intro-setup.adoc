:imagesdir: ../assets/images
[#deploy-intro]
= Module 1: Deploying your model with vLLM on OpenShift AI

== Introduction

This module covers deploying a Gen AI model with vLLM as the inference runtime on an OpenShift AI cluster.

== Learning Objectives

- Deploy an LLM with vLLM on Kubernetes 
- Understand the basics of setting up an agentic AI system with Llama Stack and K8s
- Establish foundation for performance evaluation and optimization

== Prerequisites

- Access to target deployment environments
- Basic familiarity with containers and Kubernetes concepts
- Understanding of LLM serving requirements

== Preparing our environment

You currently are working with an OpenShift cluster with OpenShift AI deployed on top of that kubernetes cluster. We have one GPU node. 

=== Install the OpenShift or Kubernetes CLI tools

The kubectl CLI tool can be used with OpenShift clusters for most operations. Please install `kubectl` or the `oc` CLI client depending on your preference. Ensure you download the appropriate tool for your operating system.

* `oc`: https://docs.okd.io/4.19/cli_reference/openshift_cli/getting-started-cli.html
* `kubectl`: https://kubernetes.io/docs/tasks/tools/#kubectl

=== Install Tekton CLI

** Run the below command to install the Tekton CLI if you do not have it already installed.
+
[source,console,role=execute,subs=attributes+]
----
curl -sL $(curl -s https://api.github.com/repos/tektoncd/cli/releases/latest | grep "browser_download_url.*_Linux_x86_64.tar.gz" | cut -d '"' -f 4) | sudo tar -xz -C /usr/local/bin tkn
tkn version
----

NOTE: This will prompt you for your computer's password.

=== Clone the workshop repository

To complete the workshop successfully, clone the workshop repository:

[source,console,role="execute"]
----
git clone https://github.com/taylorjordanNC/govai-2025.git
cd govai-2025
----
