= GovAI Summit Workshop: vLLM, Agents, and Benchmarks

Welcome to our hands-on AI workshop for OpenShift AI! This workshop provides practical experience with deploying, evaluating, and operationalizing LLMs in enterprise environments.

== Module 1: Deploying Models on OpenShift AI

Deploy and serve LLM models using vLLM and KServe on OpenShift AI. Learn to deploy models with production-ready configurations and access them via standardized APIs.

* Deploy models using KServe on OpenShift AI
* Configure vLLM runtime for optimal performance
* Access models via OpenAI-compatible APIs
* Deploy Llama Stack for agentic AI capabilities

== Module 2: Agentic AI for Operations

Build intelligent agents that can reason, plan, and execute tasks using Llama Stack and Model Context Protocol (MCP) servers.

* Configure agents with MCP tool connectivity for OpenShift
* Implement DevOps automation workflows
* Create agents that interact with live infrastructure
* Monitor and orchestrate agent workflows

== Module 3: Evaluating Model Performance

Measure and evaluate model performance using industry-standard tools to ensure models meet production requirements.

* Benchmark model performance with GuideLLM
* Evaluate accuracy with evaluation frameworks
* Interpret metrics like latency, throughput, and accuracy
* Optimize model configurations for production use cases

== ðŸŽ¯ What You'll Learn

By completing this workshop, you will be able to:

* Deploy production-ready LLM inference on OpenShift AI
* Build agentic AI systems for operational automation
* Evaluate and benchmark LLM performance and accuracy
* Configure systems to meet production requirements and SLAs

Let's get started!




