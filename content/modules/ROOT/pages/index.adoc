= Agentic AI Workshop

Welcome to our ETX AI Presales hands-on Agentic AI workshop! 

This workshop provides hands-on experience with enterprise AI deployment and agentic AI use cases. 

== üöÄ Module 1: Infrastructure Setup and Deployment

Deploy Llama Stack on OpenShift AI with vLLM inference runtime. Covers model serving, operator deployment, MCP server integration, and playground setup.

* Deploy vLLM model server with Llama 3.2 3B
* Install Llama Stack operator and core platform
* Configure OpenShift MCP server for cluster integration
* Launch web-based playground interface

== ü§ñ Module 2: Agentic AI Implementation

Build intelligent agents with tool integration and multi-step reasoning capabilities using the deployed infrastructure.

* Configure agents with MCP tool connectivity
* Implement DevOps automation workflows
* Advanced prompting and reasoning patterns
* Production-ready agent deployment strategies

== üéØ Learning Outcomes

By the end of this workshop, you will be able to:

* Deploy production-ready LLM inference servers on enterprise platforms
* Evaluate and benchmark LLM systems for performance and accuracy  
* Optimize vLLM configurations for specific use cases and constraints
* Build centralized Model-as-a-Service platforms for enterprise consumption
* Implement AI-powered development and operational automation tools
* Create intelligent agents that can interact with live infrastructure
* Design scalable, governed AI platforms that drive business value

== ‚è±Ô∏è Workshop Format

* **Duration**: 2 hours
* **Format**: Mix of theory, hands-on labs, and real-world scenarios
* **Prerequisites**: Basic familiarity with containers, Kubernetes, and agentic concepts.
* **Environment**: Access to OpenShift cluster with GPU resources and external integrations (One RHOAI on OpenShift cluster with one L4 GPU node)
* **Progression**: From basic deployment to advanced agentic automation




